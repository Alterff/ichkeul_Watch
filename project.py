# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vwXhDDCHSgleXl9alLndNl4STlKj_r96
"""

import numpy as np
import matplotlib.pyplot as plt;
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

data = pd.read_csv('/content/project.csv')

data.head()

data.drop(columns='Unnamed: 13',axis=1,inplace=True)

data.head()

yes_no_map = {' Yes': 1, ' No': 0}
data['Decision'].replace(yes_no_map,inplace=True)

data.head()

X=data.drop(columns='Decision',axis=1)
Y=data['Decision']
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)

print(X_train.shape)
print(X_test)

from sklearn.preprocessing import StandardScaler

scaler=StandardScaler()
X_train_std=scaler.fit_transform(X_train)
X_test_std=scaler.transform(X_test)

import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras

from sklearn.linear_model import LogisticRegression

# Create the logistic regression object
logistic_regression = LogisticRegression()

logistic_regression.fit(X_train, Y_train)

res = logistic_regression.predict(X_test)

accuracy = logistic_regression.score(X_test, Y_test)

print(accuracy)
print(loss)

from sklearn.metrics import confusion_matrix
import seaborn as sns

y_pred = logistic_regression.predict(X_test)
cm = confusion_matrix(Y_test, y_pred)

# Plot the confusion matrix
sns.heatmap(cm, annot=True, cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.show()

model = keras.Sequential([
      keras.layers.Flatten(input_shape=(12,)),

      keras.layers.Dense(30, activation='relu'),

       keras.layers.Dense(30, activation='relu'),


      keras.layers.Dense(2, activation='sigmoid')
])



model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train_std,Y_train,validation_split=0.1,epochs=20)

loss, accuracy = model.evaluate(X_test_std, Y_test)
print(accuracy)
print(loss)

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Testing Accuracy')
plt.title('Model Accuracy Function Evolution Diagram')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='lower right')
plt.show()

# Plot the training and testing loss curves
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Testing Loss')
plt.title('Model Loss Function Evolution Diagram')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper right')
plt.show()

y_pred=model.predict(X_test_std)

print(y_pred[0])

y_pred_lab=[np.argmax(i) for i in y_pred]

print(y_pred_lab)

input_data=(11,8,7,2,0.840188,0.0394383,26,0.783099,27,12,27.9844,89)
input_data2=np.asarray(input_data)
input_data1=input_data2.reshape(1,-1)
input_data_std=scaler.transform(input_data1)
prediction=model.predict(input_data_std)
#print(prediction)
prediction_label=[np.argmax(prediction)]
if prediction_label[0]==1:
  print("good")
else :
  print("bad")

import pickle

filename = 'trained_model.sav'
scale='scaler_model.sav'
pickle.dump(model, open(filename, 'wb'))
pickle.dump(scaler,open(scale,'wb'))

loaded_model = pickle.load(open('trained_model.sav', 'rb'))

input_data=(11,8,7,2,0.840188,0.0394383,26,0.783099,27,12,27.9844,89)
input_data2=np.asarray(input_data)
input_data1=input_data2.reshape(1,-1)
input_data_std=scaler.transform(input_data1)
prediction=loaded_model.predict(input_data_std)
#print(prediction)
prediction_label=[np.argmax(prediction)]
if prediction_label[0]==1:
  print("good")
else :
  print("bad")

